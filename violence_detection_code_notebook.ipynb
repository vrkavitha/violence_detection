{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "73288a0e",
      "metadata": {
        "id": "73288a0e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Pipeline Overview:\n",
        "\n",
        "1. Data Loading & Preprocessing:\n",
        "   - Resize to 224x224\n",
        "   - Apply CLAHE for contrast enhancement\n",
        "   - Denoise and Sharpen\n",
        "   - Normalize to [0,1]\n",
        "\n",
        "2. Data Augmentation (for class balancing):\n",
        "   - Random brightness adjustment\n",
        "   - Horizontal flip\n",
        "   - Random rotation (-20° to +20°)\n",
        "   - Zoom (0.9x to 1.1x)\n",
        "\n",
        "3. Dataset Splitting:\n",
        "   - Stratified Train/Validation/Test split (70/15/15)\n",
        "\n",
        "4. Model Architectures:\n",
        "   - VGG16 (pretrained on ImageNet, frozen base)\n",
        "   - ResNet50 (pretrained on ImageNet, frozen base)\n",
        "   - GlobalAveragePooling2D\n",
        "   - Dense(512) + Dropout(0.5)\n",
        "   - Dense(2) Softmax output\n",
        "\n",
        "5. Training:\n",
        "   - Loss: SparseCategoricalCrossentropy\n",
        "   - Optimizer: Adam\n",
        "   - ReduceLROnPlateau callback (patience=2, factor=0.3)\n",
        "\n",
        "6. Evaluation:\n",
        "   - Accuracy, Precision, Recall, F1-Score\n",
        "   - Confusion Matrix\n",
        "   - ROC AUC Score and Curve\n",
        "   - Loss & Accuracy plots\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vrkavitha/violence_detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjnyXDwCEaHV",
        "outputId": "539a33f2-866d-456e-a397-8ec72b427d3b"
      },
      "id": "XjnyXDwCEaHV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'violence_detection'...\n",
            "remote: Enumerating objects: 6005, done.\u001b[K\n",
            "remote: Total 6005 (delta 0), reused 0 (delta 0), pack-reused 6005 (from 2)\u001b[K\n",
            "Receiving objects: 100% (6005/6005), 322.58 MiB | 24.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (6041/6041), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "568455dd",
      "metadata": {
        "id": "568455dd"
      },
      "outputs": [],
      "source": [
        "DATA_DIR   = \"/content/violence_detection/dataset\"\n",
        "CATEGORIES = [\"violence\", \"non_violence\"]\n",
        "IMG_SIZE   = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7e97fbeb",
      "metadata": {
        "id": "7e97fbeb"
      },
      "outputs": [],
      "source": [
        "def apply_clahe(image):\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l,a,b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
        "    l_cl = clahe.apply(l)\n",
        "    merged = cv2.merge([l_cl, a, b])\n",
        "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3c546022",
      "metadata": {
        "id": "3c546022"
      },
      "outputs": [],
      "source": [
        "def denoise_and_sharpen(image):\n",
        "    den = cv2.fastNlMeansDenoisingColored(image, None, 7, 7, 7, 21)\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                       [-1, 5,-1],\n",
        "                       [0, -1, 0]])\n",
        "    sharp = cv2.filter2D(den, -1, kernel)\n",
        "    return sharp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6d480951",
      "metadata": {
        "id": "6d480951"
      },
      "outputs": [],
      "source": [
        "def random_augment(image):\n",
        "    # Brightness\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
        "    hsv[:,:,2] = np.clip(hsv[:,:,2] * random.uniform(0.7,1.3), 0,255)\n",
        "    image = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
        "    # Flip\n",
        "    if random.random() < 0.5:\n",
        "        image = cv2.flip(image, 1)\n",
        "    # Rotate\n",
        "    angle = random.uniform(-20, 20)\n",
        "    M = cv2.getRotationMatrix2D((IMG_SIZE/2, IMG_SIZE/2), angle, 1.0)\n",
        "    image = cv2.warpAffine(image, M, (IMG_SIZE, IMG_SIZE), borderMode=cv2.BORDER_REFLECT)\n",
        "    # Zoom\n",
        "    if random.random() < 0.5:\n",
        "        zx = zy = random.uniform(0.9,1.1)\n",
        "        image = cv2.resize(image, None, fx=zx, fy=zy)\n",
        "        h,w = image.shape[:2]\n",
        "        top = max((h-IMG_SIZE)//2,0)\n",
        "        left= max((w-IMG_SIZE)//2,0)\n",
        "        image = image[top:top+IMG_SIZE, left:left+IMG_SIZE]\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83af3712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83af3712",
        "outputId": "1a2b1376-0ab7-4ce2-ae9e-28142fe9a925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing violence:  11%|█         | 332/3034 [00:58<11:34,  3.89img/s]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Load + Preprocess\n",
        "raw, clahe, denoise = {}, {}, {}\n",
        "for cat in CATEGORIES:\n",
        "    raw[cat] = []\n",
        "    clahe[cat] = []\n",
        "    denoise[cat] = []\n",
        "    folder = os.path.join(DATA_DIR, cat)\n",
        "    file_list = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    for fname in tqdm(file_list, desc=f'Processing {cat}', unit='img'):\n",
        "        img = cv2.imread(os.path.join(folder, fname))\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        raw[cat].append(img)\n",
        "        c = apply_clahe(img)\n",
        "        d = denoise_and_sharpen(c)\n",
        "        clahe[cat].append(c)\n",
        "        denoise[cat].append(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd976a48",
      "metadata": {
        "id": "fd976a48"
      },
      "outputs": [],
      "source": [
        "# Class counts\n",
        "for cat in CATEGORIES:\n",
        "    print(f\"{cat}: {len(raw[cat])} images\")\n",
        "\n",
        "# Balance classes by augmenting smaller class\n",
        "max_ct = max(len(raw[c]) for c in CATEGORIES)\n",
        "augmented = {cat: [] for cat in CATEGORIES}\n",
        "for cat in CATEGORIES:\n",
        "    need = max_ct - len(denoise[cat])\n",
        "    pool = denoise[cat]\n",
        "    for _ in tqdm(range(need), desc=f\"Augmenting {cat}\"):\n",
        "        aug_img = random_augment(random.choice(pool))\n",
        "        augmented[cat].append(aug_img)\n",
        "\n",
        "final_counts = {cat: len(denoise[cat]) + len(augmented[cat]) for cat in CATEGORIES}\n",
        "print(\"Final counts after augmentation:\")\n",
        "for cat in CATEGORIES:\n",
        "    print(f\"{cat}: {final_counts[cat]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3a885e",
      "metadata": {
        "id": "ed3a885e"
      },
      "outputs": [],
      "source": [
        "# Pie chart\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(final_counts.values(), labels=final_counts.keys(), autopct=\"%1.1f%%\")\n",
        "plt.title(\"Class Distribution (After Balancing)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97849b25",
      "metadata": {
        "id": "97849b25"
      },
      "outputs": [],
      "source": [
        "# Grid\n",
        "def plot_big_grid(raw, clahe, denoise, categories, n=4):\n",
        "    rows = len(categories)*n\n",
        "    fig, axes = plt.subplots(rows, 3, figsize=(15, rows*3))\n",
        "    idx = 0\n",
        "    for cat in categories:\n",
        "        picks = random.sample(range(len(raw[cat])), min(n, len(raw[cat])))\n",
        "        for p in picks:\n",
        "            axes[idx,0].imshow(cv2.cvtColor(raw[cat][p], cv2.COLOR_BGR2RGB))\n",
        "            axes[idx,0].axis(\"off\")\n",
        "            axes[idx,0].set_title(f\"{cat} Original\")\n",
        "\n",
        "            axes[idx,1].imshow(cv2.cvtColor(clahe[cat][p], cv2.COLOR_BGR2RGB))\n",
        "            axes[idx,1].axis(\"off\")\n",
        "            axes[idx,1].set_title(\"CLAHE\")\n",
        "\n",
        "            axes[idx,2].imshow(cv2.cvtColor(denoise[cat][p], cv2.COLOR_BGR2RGB))\n",
        "            axes[idx,2].axis(\"off\")\n",
        "            axes[idx,2].set_title(\"Denoise+Sharpen\")\n",
        "\n",
        "            idx += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_big_grid(raw, clahe, denoise, CATEGORIES, n=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d963963d",
      "metadata": {
        "id": "d963963d"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "label_map = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n",
        "\n",
        "for cat in CATEGORIES:\n",
        "    # Combine denoised + augmented images\n",
        "    imgs = denoise[cat] + augmented[cat]\n",
        "    X.extend(imgs)\n",
        "    y.extend([label_map[cat]] * len(imgs))\n",
        "\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29817da1",
      "metadata": {
        "id": "29817da1"
      },
      "outputs": [],
      "source": [
        "# Normalize to [0,1]\n",
        "X /= 255.0\n",
        "\n",
        "print(f\"dataset: {X.shape}, labels: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f0e13b",
      "metadata": {
        "id": "b6f0e13b"
      },
      "outputs": [],
      "source": [
        "# First split train vs temp (train=70%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "# Split temp into val/test 50% each => 15% val, 15% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1d5103",
      "metadata": {
        "id": "2a1d5103"
      },
      "outputs": [],
      "source": [
        "print(f\"Train: {X_train.shape[0]} samples\")\n",
        "print(f\"Val:   {X_val.shape[0]} samples\")\n",
        "print(f\"Test:  {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb6c5a6",
      "metadata": {
        "id": "bbb6c5a6"
      },
      "outputs": [],
      "source": [
        "# Load base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# Freeze convolutional base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1)\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b168ffdc",
      "metadata": {
        "id": "b168ffdc"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2b7181",
      "metadata": {
        "id": "5b2b7181"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, target_names=CATEGORIES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbefcf58",
      "metadata": {
        "id": "bbefcf58"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739fb3c1",
      "metadata": {
        "id": "739fb3c1"
      },
      "outputs": [],
      "source": [
        "# ROC-AUC\n",
        "y_test_bin = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "roc_auc = roc_auc_score(y_test_bin, y_pred_probs)\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test_bin[:,1], y_pred_probs[:,1])\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14df6562",
      "metadata": {
        "id": "14df6562"
      },
      "outputs": [],
      "source": [
        "# Load base model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# Freeze base layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27af4018",
      "metadata": {
        "id": "27af4018"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5325de2e",
      "metadata": {
        "id": "5325de2e"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=CATEGORIES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2113af59",
      "metadata": {
        "id": "2113af59"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39af8b1e",
      "metadata": {
        "id": "39af8b1e"
      },
      "outputs": [],
      "source": [
        "y_test_bin = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "roc_auc = roc_auc_score(y_test_bin, y_pred_probs)\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test_bin[:,1], y_pred_probs[:,1])\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb232ed2",
      "metadata": {
        "id": "eb232ed2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}